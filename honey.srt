1
00:00:2,313 --> 00:00:6,703
안녕하세요 이번 과정은 Honey 프로젝트의

2
00:00:6,783 --> 00:00:10,933
사용 예시 첫번째 실습입니다 
이번 실습에서는

3
00:00:11,313 --> 00:00:12,613
실제 사용 예시를 통해서

4
00:00:12,543 --> 00:00:14,443
Honey의 사용법과 어떤식으로

5
00:00:14,373 --> 00:00:17,503
데이터를 수집 분석해서 사용하면 되는지를 다뤄보겠습니다

6
00:00:17,925 --> 00:00:23,775
구체적으로
이번 메뉴얼에서는 일부러 잘못된 데이터를 수집 해볼 것입니다 

7
00:00:23,795 --> 00:00:30,085
여기서 잘못된 데이터 혹은 품질이 낮은 데이터란 적절하게 레이블링되지 않았거나 

8
00:00:30,215 --> 00:00:32,005
특정 레이블에 대한 데이터만 적거나 많은 데이터 혹은

9
00:00:32,355 --> 00:00:34,635
특정 객체나 상황에 편향된 데이터를 말합니다

11
00:00:34,515 --> 00:00:40,317
테스트에 앞서 새로운 프로젝트를 생성하도록 하겠습니다

12
00:00:40,247 --> 00:00:41,067
기존에는

13
00:00:40,997 --> 00:00:41,937
저희가 예시로

15
00:00:43,367 --> 00:00:48,807
제공한 MNIST1부터 example1, 2가 있는데요 
test1을 만들어서 test1이

17
00:00:48,887 --> 00:00:52,497
잘 세팅된 것을 확인하고 
Data Collection으로 넘어가서

19
00:00:53,696 --> 00:00:56,776
0 레이블에 대한 데이터를 수집을 할것인데
 
20
00:00:56,786 --> 00:00:58,000
0, 1, 2

21
00:00:58,106 --> 00:00:59,496
0 레이블에 대해서

22
00:00:59,726 --> 00:1:1,056
0부터 9까지

23
00:1:1,736 --> 00:1:7,506
모든 데이터 수집을 진행하겠습니다 
일반적으로라면 0 레이블에 대해서는

24
00:1:8,066 --> 00:1:11,043
0을 작성한 데이터만 수집을 해야하지만

26
00:1:11,303 --> 00:1:11,943
여기서는

27
00:1:12,233 --> 00:1:21,934
과연 데이터를 이런 식으로 이상하게 수집을 하게되면 
어떻게 진행되는지 한번 확인해 볼 것입니다

29
00:1:22,794 --> 00:1:23,524
이런 식으로

30
00:1:24,114 --> 00:1:30,992
모든 레이블에 대해서 0부터 9까지 총 10개의 데이터를 이렇게 생성하면

31
00:1:30,995 --> 00:1:36,992
작성한 것에 대해서 아래의 이미지를 통해 현재 수집한 데이터에 대해서 확인할 수 있고

32
00:1:37,522 --> 00:1:38,102
이거를

33
00:1:38,392 --> 00:1:42,122
Construct Dataset 버튼을 통해서 데이터 셋으로 구축할 수 있습니다

35
00:1:44,544 --> 00:1:50,044
시간 상 관계로 이 모든 것을 직접 작성하진 않고 저희가

36
00:1:50,544 --> 00:1:51,754
사전에 제공한

37
00:1:52,044 --> 00:1:53,824
프로젝트 example1을 통해서

38
00:1:53,784 --> 00:1:54,304
구축한

39
00:1:54,234 --> 00:2:1,508
데이터셋을 사용하도록 하겠습니다 
여기는 0부터 9까지 각 레이블 마다 10개씩 수집이 되어 있고요 

40
00:2:1,538 --> 00:2:6,768
각 레이블별로 데이터를 확인하면 이런 식으로 조금씩 다르지만 0부터 9까지가

41
00:2:6,818 --> 00:2:8,908
작성되어있는 것을 확인할수 있습니다

43
00:2:9,695 --> 00:2:16,435
데이터셋은 이미 구축이 되어있고 
이 다음 단계인 Dataset Validation으로 넘어가도록 하겠습니다

44
00:2:21,359 --> 00:2:26,059
현재 데이터 셋에 대해서 클러스터링을 한 결과인데요

45
00:2:26,989 --> 00:2:35,339
클러스터링이 적절하게 잘 되어 있지 않은 것을 확인할수 있습니다 
보다 명확하게 보기 위해 다른 데이터셋과 비교해서 살펴보도록 하겠습니다 

46
00:2:39,385 --> 00:2:41,075
총 10,000개 데이터로 이루어 진 MNIST같은 경우에는

47
00:2:41,575 --> 00:2:45,545
이렇게 유사한 데이터가 어느 정도 섞여있기도 하지만 비교적 같은 레이블끼리

48
00:2:45,595 --> 00:2:46,865
잘 뭉쳐 있는 것을 확인할수 있습니다 

49
00:2:46,999 --> 00:2:53,135
좀 더 크게 MNIST7 총 7만개의 데이터가 모여있는 데이터셋을

51
00:2:53,755 --> 00:3:5,901
분석한 결과를 보도록 하겠습니다 
여기 보시면 가장 가운데 있는 보라색은 

54
00:3:7,721 --> 00:3:8,421
4이네요

55
00:3:9,221 --> 00:3:12,171
가운데 있는 거 4이고, 5, 1

56
00:3:13,598 --> 00:3:18,858
1과 5가 어느 정도가 유사하고 혹은 7과도 유사하다

59
00:3:19,358 --> 00:3:20,118
데이터적으로

60
00:3:20,108 --> 00:3:21,168
혹은 9와도

61
00:3:21,158 --> 00:3:24,558
어느 정도 유사성을 지니고 있다 이런 식으로 파악할 수 있는 반면

62
00:3:25,058 --> 00:3:26,658
이곳에서는

63
00:3:26,738 --> 00:3:36,719
레이블이 적절하게 매겨지지 않았기 때문에 확인하기 어렵습니다 
이를 텐서보드를 통해 좀 더 명확하게 한번 살펴보도록 하겠습니다 

64
00:3:37,129 --> 00:3:43,619
텐서보드가 한 번이 안되면 이렇게 두 번 눌러주시면 정상적으로 실행이 되구요 

65
00:3:43,819 --> 00:3:51,131
보시면 저희가 작성한 이미지를 띄워놓은 결과인데요 
마우스를 갖다 대시면 각 이미지에 대한 실제 레이블이 표시되게 됩니다 

66
00:3:52,271 --> 00:3:58,741
보시면 각 레이블은 다소 다르지만 실제 이미지는
특성에 따라서 이렇게 클러스터링을 해놓은

67
00:3:58,671 --> 00:3:59,611
결과이기 때문에

68
00:4:0,291 --> 00:4:1,411
같은 숫자들끼리

69
00:4:1,371 --> 00:4:2,491
잘 뭉쳐있고

71
00:4:2,631 --> 00:4:3,781
유사한 숫자들끼리

72
00:4:4,415 --> 00:4:5,045
가깝게

73
00:4:5,075 --> 00:4:11,389
위치한 것을 확인하실 수 있습니다 
이미지를 클릭하면 이 이미지에서 가장 가까운

75
00:4:11,999 --> 00:4:15,909
가장 유사한 데이터에 대해서 이렇게 확인하실 수 있는데요

76
00:4:16,159 --> 00:4:22,649
기본값은 코사인 유사도를 기준으로 제시하고 있고

79
00:4:22,699 --> 00:4:30,181
그 외에 유클라디안 거리를 통해서 유사한 데이터가 무엇인지 확인하실 수 있습니다 

80
00:4:30,381 --> 00:4:33,171
이렇게 작은 화면 뿐만이 아니라 여기서 출력한

81
00:4:33,161 --> 00:4:35,391
이 경로를 통해서 큰 화면으로

82
00:4:35,711 --> 00:4:41,721
텐서보드를 활성화해서 확인할 수도 있는데요 좀 더 크게 해서 보시면

84
00:4:41,651 --> 00:4:46,141
이렇게 5 1 이런 식으로 실제 저희가 메긴 레이블과 무관하게 

85
00:4:46,356 --> 00:4:55,966
데이터 분석의 결과 실제로 유사한 데이터들끼리 뭉쳐있거나 유사한 데이터들끼리 가깝게

88
00:4:55,956 --> 00:4:58,126
위치한 것을 확인할 수 있습니다

90
00:4:58,156 --> 00:5:4,449
이 외에도 다크모드를

93
00:5:4,649 --> 00:5:9,759
사용한다거나 이미지가 아닌 레이블로 표시를 한다거나 하는 다양한 기능이 있고

94
00:5:10,679 --> 00:5:11,139
현재는

95
00:5:11,069 --> 00:5:15,189
PCA를 진행한 결과지만 3차원이 아니라 2차원에 표시를 한다거나

96
00:5:17,558 --> 00:5:20,148
T-SNE 혹은 UMAP 등으로

97
00:5:20,378 --> 00:5:22,648
표시하는 방법들이 있습니다

99
00:5:25,526 --> 00:5:33,384
다시 본래 화면으로 넘어가서 이러한 데이터를 만약 학습해보면 어떻게 될까요

100
00:5:35,877 --> 00:5:37,057
이렇게 잘못 구축한

101
00:5:37,187 --> 00:5:42,307
데이터셋이기 때문에 성능이 좋지 않으리라는 것은 직관적으로 확인할 수 있지만

102
00:5:42,417 --> 00:5:46,017
어느정도 수준인지 직접 확인해 보도록 하겠습니다

103
00:5:46,097 --> 00:5:48,847
데이터 학습을 위해 비교적 좋은 알고리즘인

105
00:5:48,887 --> 00:5:54,596
CNN을 사용하고 평가 데이터 셋은 정상적으로 데이터가 작성된

106
00:5:54,526 --> 00:5:56,636
example2 그리고

107
00:5:56,596 --> 00:6:0,026
epoch는 100epoch 정도 

108
00:6:0,066 --> 00:6:0,686
100epoch...

109
00:6:1,096 --> 00:6:4,316
그리고 데이터 증강을 실행하되

111
00:6:5,386 --> 00:6:7,736
너무 많이는 하지않고 40 배 정도로만

112
00:6:7,862 --> 00:6:11,502
그리고 Outlier Filter를 켜서 

113
00:6:11,532 --> 00:6:15,252
이것에 대한 자세한 설명은 이후에 실습 과정에서 설명하도록 하겠습니다

114
00:6:15,302 --> 00:6:18,342
이렇게 CNN, sample2 dataset으로 평가를 하고

115
00:6:18,632 --> 00:6:24,192
epoch는 100epoch 데이터 증강을 40배로 하되 outlier Filter를 키는

117
00:6:24,207 --> 00:6:31,312
식으로 진행을 해보도록 하겠습니다 
데이터 전처리가 프로그래스바로 표시가 되고

119
00:6:31,352 --> 00:6:33,942
이후 이를 데이터 로더에 넣어서

120
00:6:34,622 --> 00:6:36,042
학습이 시작됩니다

121
00:6:37,744 --> 00:6:38,654
이 그래프는

122
00:6:38,584 --> 00:6:39,134
각각

123
00:6:39,154 --> 00:6:42,464
정확도와 로스를 나타냅니다 
위의 그래프(accuracy)는

125
00:6:43,414 --> 00:6:46,514
향상되는 것이 좋은 것이고 
아래 그래프(loss)는 0에

126
00:6:46,444 --> 00:6:47,294
가깝게

127
00:6:47,314 --> 00:6:48,194
수렴되는 것이

128
00:6:48,124 --> 00:6:56,604
좋은 그래프입니다 
잠시 기다려 보시면 이제 학습이 완료되고 이렇게

130
00:6:56,742 --> 00:7:0,502
최종적인 성능과 함께 총 소요시간 그리고

131
00:7:0,882 --> 00:7:3,472
실제로 틀린 데이터에 대해서 이렇게 표시를 하는데요

132
00:7:4,242 --> 00:7:5,542
이 7이라는 건

133
00:7:5,622 --> 00:7:11,993
레이블이 7이라 건 제가 직관적으로 알 수 있지만 
잘못된 데이터를 학습한 모델은 이것에 대해서 0 이라고 예측을 했고 

134
00:7:11,999 --> 00:7:18,833
5에 대해서는 8이라고 예측을 했고, 
다른 데이터 0에 대해서 7이라고 예측하는 등

135
00:7:18,763 --> 00:7:30,184
알수없는 기준으로 예측을 하고있는 것을 볼 수 있습니다 
성능에서도 Accruacy가 학습 데이터에 대해서는 0.89로 굉장히 의아하게 잘 나타났지만 

136
00:7:30,244 --> 00:7:41,723
Validation Accracy는 0.07로 거의 맞추지 못한 것을 알 수 있습니다 
총 200개의 데이터 셋 중에서 181개를 틀렸네요  

137
00:7:41,653 --> 00:7:44,573
또한 학습 성능이 나쁘지 않게 나타났다고 하더라도

138
00:7:44,563 --> 00:7:48,113
이를 다른 테스트셋에 대해서 평가에 볼 수 있습니다

141
00:7:50,775 --> 00:8:9,958
저희는 example1에 있고 사용하는 모델은 cnn,
cnn과 Augmentation을 같이 수행한 모델을 선택할 것이고 

142
00:8:9,888 --> 00:8:10,678
MNIST1 데이터셋을 평가 해보도록 하겠습니다 
이렇게 보시면 총 10,000개 데이터 셋 중에서 8,851개를 틀렸다는 것을 확인할수 있습니다

143
00:8:12,174 --> 00:8:14,014
아무래도 이렇게 틀린 것에 대해서는

144
00:8:14,124 --> 00:8:17,544
상위 300개 정도만 표시하도록

145
00:8:17,574 --> 00:8:23,281
해놨기 때문에 모든 데이터가 다 표시 되지는 않지만 같은 6에 대해서도

146
00:8:23,331 --> 00:8:30,811
3, 2, 8 이런식으로 
알 수 없는 기준으로 데이터를 판단하고 있는 것을 확인할수 있습니다 

147
00:8:31,011 --> 00:8:40,240
그 다음으로는 인퍼런스 단계로 넘어가 보도록 하겠습니다 
인퍼런스 단계에서는 최대 3개까지 서로 다른 학습 시킨 

148
00:8:40,330 --> 00:8:42,940
모델들의 성능을 동시에 출력하고

149
00:8:42,960 --> 00:8:43,990
비교할 수 있습니다

151
00:8:45,981 --> 00:8:49,306
저희는 방금 전에 학습 시킨

152
00:8:49,746 --> 00:8:57,916
example1에 CNN_AUG랑 
MNIST1에 대해서 학습 시킨 CNN_AUG

156
00:8:57,846 --> 00:8:58,516
그리고

157
00:8:58,866 --> 00:9:0,166
정상적인 Dataset인

158
00:9:0,396 --> 00:9:1,846
example2에 대해서

159
00:9:1,926 --> 00:9:3,436
CNN_AUG 학습 시킨 모델을

161
00:9:4,331 --> 00:9:9,621
올려놓고 데이터를 작성을 해보도록 하겠습니다 
살펴보시면

162
00:9:9,821 --> 00:9:11,001
어 의외로

163
00:9:11,411 --> 00:9:16,371
모든 모델이 잘 맞췄습니다 
Text Detect 옵션을 사용한다고 하면

164
00:9:17,514 --> 00:9:20,274
정상적으로 학습시킨 모델은 0으로 오히려 더 확실하게 예측한 반면,

165
00:9:20,534 --> 00:9:29,809
저희가 잘못 학습한 모델은 8로 예측하는 것을 확인할수 있습니다 
다른 데이터를 한 번 작성해보도록 하겠습니다

167
00:9:32,611 --> 00:9:33,521
사실 저도

168
00:9:34,081 --> 00:9:34,421
조금

169
00:9:34,351 --> 00:9:35,831
애매하게 잘 작성을 헤맸지만

170
00:9:35,851 --> 00:9:36,371
1이라고

171
00:9:36,331 --> 00:9:39,941
작성을 한 결과인데 8이라고 예측을 했고 나머지 두 개는

172
00:9:39,971 --> 00:9:41,371
잘 예측을 한 것을 볼 수 있습니다


173
00:9:42,301 --> 00:9:47,241
Text Detect 옵션을 끄게되면 그래도 이 2개 모델은 4나 7, 9의 가능성을 제시하긴 했지만 

174
00:9:47,261 --> 00:9:50,081
여전히 1이라고 예측을 했고

175
00:9:51,017 --> 00:9:54,147
저희가 방금 학습 시킨 모델은 4로 예측한 것을

176
00:9:54,077 --> 00:9:56,307
확인할수 있습니다 
1에 대한 확률은

177
00:9:56,327 --> 00:9:59,023
굉장히 낮네요 

178
00:9:59,033 --> 00:9:59,803
마지막으로 다른

179
00:10:0,003 --> 00:10:3,003
숫자를 한번 더 진행하도록 하겠습니다 

180
00:10:3,353 --> 00:10:4,723
4에 대해서도

181
00:10:4,753 --> 00:10:09,623
다른 2개 모델은 정상적으로 예측을 했고 
이 모델은 예측을 제대로 하지 못했네요 

182
00:10:09,630 --> 00:10:14,000
Text Detect 옵션을 키면

183
00:10:13,930 --> 00:10:15,110
이 모델 같은 경우에는

184
00:10:15,040 --> 00:10:18,320
이렇게 Text Detect 옵션을 켰더니 오히려 

186
00:10:18,340 --> 00:10:19,160
6에 대한

187
00:10:19,090 --> 00:10:22,280
확률이 조금 올라가긴 했지만 여전히 가장 높은 확률로 4를

188
00:10:22,210 --> 00:10:23,570
제시하고 있고 여기서도

189
00:10:23,530 --> 00:10:24,650
4를 제시하고 있습니다

190
00:10:28,655 --> 00:10:30,345
Stroke(펜의 굵기)를 한 번 바꿔볼까요 

192
00:10:30,425 --> 00:10:31,725
Stroke를 바꿔서

193
00:10:31,805 --> 00:10:33,105
아주 작게 한 번

194
00:10:33,215 --> 00:10:35,985
써보도록 하겠습니다 

195
00:10:35,915 --> 00:10:40,665
이렇게 Text Detect 옵션을 썼기 때문에 구석에 작게 썼다고 하더라도 크게

196
00:10:40,595 --> 00:10:41,715
확대되게 되고

197
00:10:42,575 --> 00:10:47,485
이렇게 작성을 했더니 MNIST1은 6이라고 예측을 했고 

199
00:10:47,525 --> 00:10:55,824
example2는 오히려 잘 예측을 한 것을 볼 수 있네요 
Detect 옵션을 꺼볼까요 

200
00:10:55,999 --> 00:11:01,484
Text Detect 옵션을 껐더니 이 데이터가 이렇게 프리 프로세싱된 것을 확인할 수 있고 

201
00:11:01,814 --> 00:11:07,384
이런 데이터를 줬다간 어떤 모델도 정상적으로 예측하지 못하는 것을 확인할수있습니다 

202
00:11:07,545 --> 00:11:12,005
마지막으로 로그입니다 이 로그는 저희가 여태까지 학습 시킨 모델에 대해서

203
00:11:12,415 --> 00:11:14,765
확인할 수 있는 결과물이고 이것들을

204
00:11:14,935 --> 00:11:19,695
저희가 특정 값을 기준으로 오름차순 내림차순으로 확인할수 있으며

205
00:11:19,755 --> 00:11:27,952
여기 오른쪽에 제시된 로그 네임을 통해서 
당시에 학습했던 로그 정확히는 틀렸던 이미지에 대한 정보를 불러올 수 있습니다 

206
00:11:27,982 --> 00:11:31,372
여기서는 example1

207
00:11:31,512 --> 00:11:33,142
Aug_CNN, example2

209
00:11:33,852 --> 00:11:36,832
라고 하는건데 그래서 example1 첫 번째는

210
00:11:37,062 --> 00:11:39,742
현재 학습한 학습용으로 사용한

211
00:11:39,672 --> 00:11:41,482
데이터 셋에 대한 프로젝트명

212
00:11:41,476 --> 00:11:44,486
그 다음으로는 Augmentaion 여부, 알고리즘

213
00:11:44,536 --> 00:11:46,046
그리고 평가용으로 사용한 데이터 셋입니다

214
00:11:46,176 --> 00:11:51,516
이거를 누르게 되면 저희가 이전에 200개중에 181개를 틀렸던 모델 데이터가 

215
00:11:51,576 --> 00:11:56,516
블러와지면서 과거에 틀렸던 로그 기록이 불러와지겠습니다

216
00:11:58,238 --> 00:12:3,228
이상으로 Honey Use Case #1에 대한 실습과정을 마치도록 하고 

217
00:12:3,358 --> 00:12:5,238
이후에 Use Case #2에서는 

219
00:12:5,408 --> 00:12:7,578
좀 더 심도 깊게 데이터 증강이나

220
00:12:7,928 --> 00:12:8,478
혹은

221
00:12:8,468 --> 00:12:9,858
이런 세부적인 옵션들을

223
00:12:10,868 --> 00:12:19,260
아까 데이터 수집의 이런 세부적인 옵션들을 사용하는 방법에 대해서 다뤄 보도록 하겠습니다 

224
00:12:19,868 --> 00:12:25,260
감사합니다

